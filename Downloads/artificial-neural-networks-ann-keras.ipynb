{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "Created by: Sangwook Cheon\n",
    "\n",
    "Date: Dec 23, 2018\n",
    "\n",
    "This is step-by-step guide to Artificial Neural Networks (ANN), which I created for reference. I added some useful notes along the way to clarify things. This notebook's content is from A-Z Datascience course, and I hope this will be useful to those who want to review materials covered, or anyone who wants to learn the basics of ANN.\n",
    "\n",
    "## Content:\n",
    "### IMPLEMENTATION\n",
    "### 1. Data preprocessing\n",
    "### 2. Build the Keras model\n",
    "### 3. Compile and fit the model\n",
    "### 4. Make predictions and determine accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#problems\n",
    "1.How are Neural Networks modelled?\n",
    "2.How can Neural Networks be Unsupervised?\n",
    "3.How do Neural Networks get the optimal Weights and Bias values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#answer\n",
    "1.Artificial neural networks are modelled from biological neurons.\n",
    "a.The connections of the biological neuron are modeled as weights.\n",
    "b.A positive weight reflects an excitatory connection, while negative values mean inhibitory connections.\n",
    "c.All inputs are modified by a weight and summed. This activity is referred to as a linear combination.\n",
    "\n",
    "2.Neural Networks are used in unsupervised learning to learn better representations of the input data.\n",
    " a.Neural networks can learn a mapping from document to real-valued vector in such a way that resulting vectors are similar for documents with similar content. This can be achieved using autoencoders which is a model that is trained to reconstruct the original vector from a smaller representation with reconstruction error as a cost function.\n",
    "b.There are neural networks that are specifically designed for clustering as well. The most widely known is the self-organizing maps (SOM).\n",
    "\n",
    "\n",
    "3.The neural networks get the optimal weights and bias values through an Error Gradient.\n",
    "a.The gradient value is calculated from a selected algorithm called backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# Some notes on ANNs\n",
    "\n",
    "## The Neuron\n",
    "Axon: Transmitters of signals\n",
    "Dentrites: Receivers of signals\n",
    "\n",
    "The ANNs imitate the behavior of human brain. Each neuron receives certain inputs from the previous neurons, and process that information to send signals to others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b701497ce3e8ef2491c173f065a85e5b2cc57d22"
   },
   "source": [
    "# The Activation Function\n",
    "\n",
    "Options:\n",
    "* Threshold Function\n",
    "* Sigmoid Function\n",
    "* Rectified Linear Unit (ReLU)\n",
    "* Tanh\n",
    "\n",
    "For binary classification, Threhold Function or Sigmoid Function should be used.\n",
    "It is common to apply ReLU to hidden layers, and Sigmoid to the final layer to produce results.\n",
    "\n",
    "# Dataset overview (used in this kernel)\n",
    "A bank is trying to see whether or not customers will be leaving the bank, based on various information about each customer. These features include Credit Score, Gender, Balance, etc. (Please see the view of the dataset below). We will apply ANN to find meaningful correlations between these independent variables, and determine if a customer will leave or stay in the bank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f3208f3cdeea079a49e17218853693baeef2d6d8"
   },
   "source": [
    "### 1. Data processing\n",
    "Data processing is crucial for ANNs to work properly. All steps are required, including feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8371e21511b51ed9e6683202a64586b148d860bf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset = pd.read_csv('../input/Churn_Modelling.csv')\n",
    "\n",
    "#include relevant columns within x and y\n",
    "x = dataset.iloc[:, 3:13]\n",
    "y = dataset.iloc[:, 13]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7a609ba8b7027e8558b50755632fcd7bb8e7af66"
   },
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d30e5fc34a285f25c29bec87a805bcc6cb0243d9"
   },
   "outputs": [],
   "source": [
    "#deal with categorical data --> encode them\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_x = LabelEncoder()\n",
    "x.iloc[:, 1] = labelencoder_x.fit_transform(x.iloc[:, 1]) #applying on Geography\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "24f23065dbb15f14ea43829aa3b097270497b692"
   },
   "outputs": [],
   "source": [
    "#apply encoder on Gender as well\n",
    "labelencoder_x_2 = LabelEncoder()\n",
    "x.iloc[:, 2] = labelencoder_x_2.fit_transform(x.iloc[:, 2]) #applying on Gender\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7de84c74e53a85a3c0c725bd6d3530b69d9b0305"
   },
   "outputs": [],
   "source": [
    "#One hot encoding. \n",
    "\n",
    "from keras.utils import to_categorical\n",
    "encoded = pd.DataFrame(to_categorical(x.iloc[:, 1]))\n",
    "#no need to encode Gender, as there are only two categories\n",
    "\n",
    "x = pd.concat([encoded, x], axis = 1)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5998ec5bda62b9edb55fa52914185b6e93f6947c"
   },
   "outputs": [],
   "source": [
    "#Dropping the existing \"geography\" category, and one of the onehotcoded columns.\n",
    "\n",
    "x = x.drop(['Geography', 0], axis = 1)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8d8772d25870c9d335c2903d28104b1ff080f7d3"
   },
   "outputs": [],
   "source": [
    "#train and test set split, and feature scaling\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5b1bbdc20ae35310e2febf6a09cf95a60485a50c"
   },
   "source": [
    "### 2. Build the model using Keras\n",
    "ANN with many hidden layers is one of the branches of Deep Learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "700cd43820112a6092fc08f7083cb6f8d7d8b3ce"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense #to add layers\n",
    "\n",
    "#there is no rule on how many nodes each hidden layer should have\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 11))\n",
    "#init --> initialize weights according to uniform distribution\n",
    "#input_dim is required for the first hidden layer, as it is the first starting point. --> number of nodes.\n",
    "#output_dim --> number of nodes of the hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n",
    "#input_dim --> remove it as it already knows what to expect.\n",
    "\n",
    "#the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "#output_dim should be 1, as output is binary outcome, and activation should be 'sigmoid'\n",
    "#If dependent variables have more than two categories, use activation = 'softmax'\n",
    "\n",
    "#compile the model --> backpropagation -> gradient descent\n",
    "classifier.compile(optimizer = 'adam', loss = \"binary_crossentropy\", metrics = ['accuracy'])\n",
    "#optimizer = algorithm to find the optimal set of weights in ANN\n",
    "#loss = functions that should be optimized. if more than two categories, use \"categorical_crossentropy\"\n",
    "#metrics = criterion used to calculate the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "25d3eb64cec180890c80f5c11871eedfb8bbd4c6"
   },
   "source": [
    "Now let's run the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "db0150ef4c7002d523ee84083bcb23d8fe7c0060"
   },
   "outputs": [],
   "source": [
    "classifier.fit(X_train, Y_train, batch_size = 10, nb_epoch = 20)\n",
    "#batch_size = the number of observations after which you want to update the weights\n",
    "#           batch size and epochs should be tuned through experiments.\n",
    "#epoch = going through the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7ce5632b5ca38561da77c123c65e300c5542c3ed"
   },
   "outputs": [],
   "source": [
    "#predicting the results\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5) #to classify each probability into True or False\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "print (cm, '\\n\\n', y_pred[:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "11cf80242070f17e95261122b42fe9197e470988"
   },
   "outputs": [],
   "source": [
    "#accuracy\n",
    "print ((1548 + 139)/2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c47e50939c7e1a8978f51654190bcdd6155f6939"
   },
   "source": [
    "The fact that accuracy on train and test set are similar shows that the model did not overfit on the train set. Hyperparameters can be tuned to obtain better results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
